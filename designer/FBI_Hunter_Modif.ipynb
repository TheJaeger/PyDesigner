{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orginial pyFBI script by Hunter\n",
    "Modified to support rapid debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------\n",
    "# Package Management\n",
    "#---------------------------------------------------------------------\n",
    "import sys as sys\n",
    "import os # mkdir\n",
    "import os.path as op # path\n",
    "import numpy as np # array, ndarray\n",
    "import numpy.matlib as npm\n",
    "import nibabel as nib\n",
    "import scipy as sp\n",
    "from scipy.io import loadmat\n",
    "import math\n",
    "from fitting.dwipy import vectorize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fiber ball imaging (FBI) analysis \n",
      "\n",
      "\n",
      " Loading image data...\n",
      "\n",
      " Loading b-value table...\n",
      "\n",
      "\n",
      " Loading gradient table...\n",
      "\n",
      "\n",
      " Loading binary brain mask...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "FBI Fit:   0%|          | 0/61127 [00:00<?, ?vox/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61127,)\n",
      "(208, 61127)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sid/miniconda3/envs/dmri/lib/python3.7/site-packages/ipykernel_launcher.py:384: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "FBI Fit:   1%|          | 569/61127 [00:27<49:06, 20.56vox/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0caf81bf358a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;31m# For references to alm and clm see FBI papers, they (alm and clm) are defined in all of them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0malm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgn\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mb0n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# DWI signal SH coefficients (these are complex)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0malm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0ma00\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m \u001b[0;31m# the imaginary part is on the order of 10^-18 (this is for zeta)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpinv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dmri/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mpinv\u001b[0;34m(a, rcond, hermitian)\u001b[0m\n\u001b[1;32m   2001\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2002\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2003\u001b[0;31m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhermitian\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhermitian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2005\u001b[0m     \u001b[0;31m# discard small singular values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msvd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dmri/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->DdD'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->ddd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1662\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define study/dataset specifics\n",
    "fn = 'dwi_preprocessed'\n",
    "root = '/home/sid/Desktop/IAM_Test/out'\n",
    "sh_path = '/home/sid/Repos/PyDesigner/designer/fitting/spherical_grid.csv'\n",
    "\n",
    "# assumes bval, bvec and image files have same leading name (variable: fn [see above])\n",
    "dataIn = op.join(root, fn + '.nii')\n",
    "btIn = op.join(root, fn + '.bval')\n",
    "gtIn = op.join(root, fn + '.bvec')\n",
    "DTIn = op.join(root, 'metrics', 'DT.nii')\n",
    "\n",
    "# get a hdr for a template to write out images later\n",
    "# need to automate this as well...\n",
    "hdr = nib.load(op.join(root,'B0.nii'))\n",
    "\n",
    "fn_mask = op.join(root,'brain_mask.nii') # must provide brain mask currently (should automate)\n",
    "outdir = op.join(root, 'metrics_debug')\n",
    "\n",
    "bval = 6\n",
    "degree = 6\n",
    "degree_rec = 6\n",
    "Dn = 1.5\n",
    "D0 = 3.0\n",
    "pkT = 0.4\n",
    "voxSize = 3.0\n",
    "\n",
    "rectification_flag = 1 # Do (1) or don't do (0) fODF rectification\n",
    "fbwm_flag = 1 # Do (1) or don't do (0) FBI WM model (FBWM)\n",
    "\n",
    "print('\\n Fiber ball imaging (FBI) analysis \\n')\n",
    "\n",
    "print('\\n Loading image data...')\n",
    "# Load in the DWI image data\n",
    "tmp = nib.load(op.join(root,fn + '.nii'))\n",
    "img = np.array(tmp.dataobj)\n",
    "\n",
    "print('\\n Loading b-value table...\\n')\n",
    "bt = np.rint(np.loadtxt(btIn)) # load the b-val table\n",
    "bt_unique = np.unique(bt).astype('int') # get the unique b-values\n",
    "\n",
    "print('\\n Loading gradient table...\\n')\n",
    "gt = np.loadtxt(gtIn).T # load in the gradient file\n",
    "\n",
    "print('\\n Loading binary brain mask...')\n",
    "# load in binary brain mask\n",
    "tmp = nib.load(fn_mask)\n",
    "mask = np.array(tmp.dataobj).astype(bool)\n",
    "\n",
    "# split out the b0 images (should maybe flag)\n",
    "b0 = img[:,:,:, bt == 0]\n",
    "b0 = np.mean(b0,axis = 3)\n",
    "\n",
    "# reshape (vectorize) the b0 and DWI image data\n",
    "b0 = vectorize(b0, mask)\n",
    "img = vectorize(img, mask)\n",
    "print(b0.shape)\n",
    "print(img.shape)\n",
    "\n",
    "if fbwm_flag == 1:\n",
    "    # if FBWM is slectted, then split the gradients for DKI out\n",
    "    tmp = nib.load(DTIn)\n",
    "    DT = np.array(tmp.dataobj)\n",
    "    DT = vectorize(DT, mask).T\n",
    "    gt1 = gt[bt == 1000, :]\n",
    "    gt2 = gt[bt == 2000, :]\n",
    "    img1 = img[bt == 1000, :]\n",
    "    img2 = img[bt == 2000, :]\n",
    "    \n",
    "# Get FBI gradients and image\n",
    "gt = gt[bt == bval*10**3,:] # FBI gradients\n",
    "img = img[bt == bval*1000, :] # FBI image data\n",
    "\n",
    "# HERE will be the SH basis set calculation...\n",
    "# get the harmonics we will need\n",
    "degs = np.arange(degree + 1)\n",
    "\n",
    "l_tot = 2*degs + 1 # total harmonics in the degree\n",
    "l_num = 2 * degs[::2] + 1 # how many per degree (evens only)\n",
    "harmonics = []\n",
    "sh_end = 1 # initialize the SH set for indexing\n",
    "\n",
    "for h in range(0,len(degs[::2])):\n",
    "    sh_start = sh_end + l_num[h] - 1\n",
    "    sh_end = sh_start + l_num[h] - 1\n",
    "    harmonics.extend(np.arange(sh_start,sh_end+1))\n",
    "\n",
    "# Currently, the rectificaiton and original MUST have same degree,\n",
    "# not sure why, will have to dig deeper...\n",
    "if rectification_flag == 1:\n",
    "\n",
    "    degs = np.arange(degree_rec + 1)\n",
    "\n",
    "    l_tot = 2*degs + 1\n",
    "    l_num = 2 * degs[::2] + 1\n",
    "    harmonics_rec = []\n",
    "    sh_end = 1\n",
    "\n",
    "    for h in range(0,len(degs[::2])):\n",
    "        sh_start = sh_end + l_num[h] - 1\n",
    "        sh_end = sh_start + l_num[h] - 1\n",
    "        harmonics_rec.extend(np.arange(sh_start,sh_end+1))\n",
    "\n",
    "# Define the azimuthal (phi) and polar(theta) angles for our spherical exapnsion\n",
    "# using the experimentally defined gradients from the scanner\n",
    "theta = np.arccos(gt[:,2])\n",
    "phi = np.arctan2(gt[:,1],gt[:,0])\n",
    "\n",
    "# This was from Russel (I made his mat file into a text file here)\n",
    "# this would be used for the ODF exapnsion which hasnt' been implemented yet\n",
    "spherical_grid = np.genfromtxt(sh_path, delimiter=\",\") # this is only HALF-SPHERE!\n",
    "S1 = spherical_grid[:,0] # theta, i think\n",
    "S2 = spherical_grid[:,1] # phi, i think\n",
    "AREA = spherical_grid[:,2] # need the area since it is impossible to get exact isotropic (uniform) sampling\n",
    "\n",
    "# initialze the SH basis set variable\n",
    "B = np.zeros((len(gt),np.sum(l_num)),dtype=np.complex,order = 'F') # This is for the dMRI SH expasion\n",
    "H = np.zeros((len(S1),np.sum(l_num)),dtype=np.complex,order = 'F') # This is for ODF creation (once it happens)\n",
    "\n",
    "if fbwm_flag == 1:\n",
    "\n",
    "    # SH basis set for the DKI data, just in case...\n",
    "    B1 = np.zeros((len(gt1),np.sum(l_num)),dtype=np.complex,order='F')\n",
    "    B2 = np.zeros((len(gt2),np.sum(l_num)),dtype=np.complex,order='F')\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for n in degs:\n",
    "    for m in range(-n,n+1):\n",
    "\n",
    "        if (n % 2) == 0:\n",
    "\n",
    "            # FBI SH basis set generation\n",
    "            B[:,cnt] = sp.special.sph_harm(m,n,phi,theta)\n",
    "            H[:,cnt] = sp.special.sph_harm(m,n,S2,S1)\n",
    "\n",
    "\n",
    "            if fbwm_flag == 1: # DKI SH basis sets\n",
    "\n",
    "                theta1 = np.arccos(gt1[:,2])\n",
    "                phi1 =  np.arctan2(gt1[:,1],gt1[:,0])\n",
    "\n",
    "                theta2 = np.arccos(gt2[:,2])\n",
    "                phi2 =  np.arctan2(gt2[:,1],gt2[:,0])\n",
    "\n",
    "                B1[:,cnt] = sp.special.sph_harm(m,n,phi1,theta1)\n",
    "                B2[:,cnt] = sp.special.sph_harm(m,n,phi2,theta2)\n",
    "\n",
    "            cnt = cnt + 1\n",
    "\n",
    "idx_Y = 0\n",
    "Pl0 = np.zeros((len(harmonics),1),order = 'F') # need Legendre polynomial Pl0\n",
    "gl = np.zeros((len(harmonics),1),order = 'F') # calculate correction factor (see original FBI paper, Jensne 2016)\n",
    "\n",
    "for l in degs[::2]:\n",
    "\n",
    "    Pl0[idx_Y:idx_Y+(2*l+1),:] = (np.power(-1,l/2)* np.math.factorial(l)) / (np.power(4,l/2)*np.power(np.math.factorial(l/2),2))*np.ones((2*l+1,1))\n",
    "    gl[idx_Y:idx_Y+(2*l+1),:] = (np.math.factorial(l/2)*np.power(bval*D0,(l+1)/2))/sp.special.gamma(l+3/2)*sp.special.hyp1f1((l+1)/2,l+3/2,-bval*D0)*np.ones((2*l+1,1))\n",
    "    idx_Y = idx_Y + (2*l+1)\n",
    "\n",
    "Pl0 = np.squeeze(Pl0)\n",
    "gl = np.squeeze(gl)\n",
    "\n",
    "# initialize the outputs\n",
    "SH = np.zeros((len(harmonics),img.shape[1]), dtype = 'complex', order = 'F') # will hold the clm (SH coefficients)\n",
    "#SH_reshape = np.zeros((img.shape[1]),len(harmonics)), dtype = 'complex',order = 'F') # This would be to read out SH image to load into MRTrix3\n",
    "zeta = np.zeros(img.shape[1],order = 'F') # zeta (see original FBI paper)\n",
    "faa = np.zeros(img.shape[1],order = 'F') # FAA (see McKinnon 2018, Moss 2019)\n",
    "\n",
    "if rectification_flag == 1:\n",
    "\n",
    "    # If rectificaion is selected: SH_rec will hold the rectified clm's (SH coefficients corected)\n",
    "    SH_rec = np.zeros((len(harmonics_rec),img.shape[1]), dtype = 'complex',order = 'F')\n",
    "\n",
    "if fbwm_flag == 1: # initialize FBWM metrics, if selected\n",
    "\n",
    "    De = np.zeros((3,3,img.shape[1]), order = 'F')\n",
    "    aDT = np.zeros((6,img.shape[1]), order = 'F')\n",
    "    cost_fn = np.zeros((100,img.shape[1]), order = 'F')\n",
    "\n",
    "    iDT_img = np.zeros((3,3,img.shape[1]), order = 'F')\n",
    "    iaDT_img = np.zeros((3,3,img.shape[1]), order = 'F')\n",
    "\n",
    "    De_mean = np.zeros(img.shape[1], order = 'F')\n",
    "    De_ax = np.zeros(img.shape[1], order = 'F')\n",
    "    De_rad = np.zeros(img.shape[1], order = 'F')\n",
    "    De_fa = np.zeros(img.shape[1], order = 'F')\n",
    "\n",
    "    # these three are used in the cost function of FBWM\n",
    "    BT = bt_unique[1:]/1000; # holds the b-vlaues (usually, 1, 2 and usually either 4, 5 or 6)\n",
    "    GT = [gt1,gt2,gt] # holds all b-vale gradient vectors\n",
    "    ndir = [len(B1), len(B2),len(B)] # holds the number of directions for each b-values\n",
    "\n",
    "# get the entire set of voxel integers as an array\n",
    "voxList = np.arange(0,img.shape[1], dtype = int)\n",
    "inputs = tqdm(\n",
    "    voxList,\n",
    "    desc='FBI Fit',\n",
    "    unit='vox',\n",
    ")\n",
    "# loop over those voxels\n",
    "for vox in inputs:\n",
    "\n",
    "    b0n = b0[vox] # get b0 (non-diffusion weighted) value (i.e., starting point for decay)\n",
    "    imgn = img[:,vox] # get the DWI value for each gradient direction\n",
    "\n",
    "    # For references to alm and clm see FBI papers, they (alm and clm) are defined in all of them\n",
    "    alm = np.dot(np.linalg.pinv(B),(imgn/b0n)) # DWI signal SH coefficients (these are complex)\n",
    "    alm[np.isnan(alm)] = 0\n",
    "    a00 = alm[0].real # the imaginary part is on the order of 10^-18 (this is for zeta)\n",
    "\n",
    "    clm = alm*gl[0]*np.power(np.sqrt(4*np.pi)*alm[0]*Pl0*gl,-1) # fODF SH coefficients (these are complex)\n",
    "    c00 = clm[0]\n",
    "    clm = clm/c00\n",
    "    clm = clm*(1/np.sqrt(4*np.pi))\n",
    "\n",
    "    SH[:,vox] = clm\n",
    "\n",
    "    # need to figure out how to do peak detection (on this variable and then read out odf structures like in MATLAB code)\n",
    "    # only the real part would be read out but that would need to be done later on after the rectification process below\n",
    "    ODF = np.matmul(H,clm)\n",
    "\n",
    "    # Here is where the fODF rectifcation begins\n",
    "    # It is simple and uses a bi-section algorithm to find the ONLY root\n",
    "    # There is only 1 root (see Optimized Rectificaion paper, Moss/Jensen 2020)\n",
    "    # This will eliminate all negative peaks (and some small spurious peaks that are noise induced)\n",
    "    # Makes the fODF completely positive\n",
    "\n",
    "    if rectification_flag == 1:\n",
    "\n",
    "        # fODF rectification\n",
    "        fODF = ODF.real # grab real part of the fODF\n",
    "        fODF[np.isnan(fODF)] = 0\n",
    "        Fmax = np.max(fODF) # get the max peak value of the ODF\n",
    "\n",
    "        lB = 0 # initial lower bound\n",
    "        uB = Fmax # initial upper bound\n",
    "\n",
    "        M = 1 # initialze iteration counter\n",
    "        Mmax = 1000 # max iterations (could prbably be 100 too)\n",
    "\n",
    "        if Fmax > 0:\n",
    "            while M <= Mmax:\n",
    "\n",
    "                # BEGIN: bi-section algorithm\n",
    "                midpt = (lB + uB)/2\n",
    "                fODF_lB = np.sum((np.abs(fODF - lB) - fODF - lB)*AREA,0)\n",
    "                fODF_midpt = np.sum((np.abs(fODF - midpt) - fODF - midpt)*AREA,0)\n",
    "\n",
    "                if fODF_midpt == 0 or (uB - lB)/2 < 10**-8:\n",
    "\n",
    "                    EPS = midpt\n",
    "\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "\n",
    "                    M = M + 1\n",
    "\n",
    "                    if np.sign(fODF_midpt) == np.sign(fODF_lB):\n",
    "\n",
    "                        lB = midpt\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        uB = midpt\n",
    "                # END: bi-section algorithm\n",
    "\n",
    "            # Subract solution from each ODF point\n",
    "            ODF = (1/2)*(np.abs(ODF - EPS) + ODF - EPS)\n",
    "            ODF = ODF.real\n",
    "\n",
    "            odf_pts = np.arange(ODF.size)\n",
    "\n",
    "            # due to numerical error, we manually set\n",
    "            # very very very tiny peaks to zero afte the fact...\n",
    "            for p in odf_pts:\n",
    "                if ODF[p] > -10**-8 and ODF[p] < 0:\n",
    "                    ODF[p] = 0\n",
    "                elif ODF[p] < 10**-8 and ODF[p] > 0:\n",
    "                    ODF[p] = 0\n",
    "\n",
    "        # Re-expand the rectified fODF into SH's\n",
    "        clm_rec = np.matmul(AREA*ODF,np.conj(H))\n",
    "        clm = clm_rec\n",
    "        c00 = clm[0]\n",
    "        clm = clm/c00\n",
    "        clm = clm*(1/np.sqrt(4*np.pi))\n",
    "\n",
    "        SH_rec[:,vox] = clm\n",
    "\n",
    "    # zeta and FAA calculations\n",
    "    # NOTE: zeta is not affected by the rectification, only FAA\n",
    "    zeta[vox] = a00*np.sqrt(bval)/np.pi\n",
    "    faa[vox] = np.sqrt(3*np.sum(np.abs(clm[1:6]**2))/(5*np.abs(clm[0])**2 + 2 * np.sum(np.abs(clm[1:6]**2))))\n",
    "\n",
    "    # BEGIN: construct axonal DT (aDT)\n",
    "\n",
    "    c00 = clm[0]\n",
    "    c2_2 = clm[1]\n",
    "    c2_1 = clm[2]\n",
    "    c20 = clm[3]\n",
    "    c21 = clm[4]\n",
    "    c22 = clm[5]\n",
    "\n",
    "    A11 = ((np.sqrt(30)/3)*c00 - (np.sqrt(6)/3)*c20 + c22 + c2_2)\n",
    "    A22 = ((np.sqrt(30)/3)*c00 - (np.sqrt(6)/3)*c20 - c22 - c2_2)\n",
    "    A33 = ((np.sqrt(30)/3)*c00 + (2*np.sqrt(6)/3)*c20)\n",
    "\n",
    "    A12 = (1j*(c22 - c2_2))\n",
    "    A13 = ((-c21 + c2_1))\n",
    "    A23 = (1j*(-c21 - c2_1))\n",
    "\n",
    "    aDT = np.array([A11, A12, A13, A12, A22, A23, A13, A23, A33]).real\n",
    "    aDT = 1/(c00*np.sqrt(30))*aDT\n",
    "    iaDT = np.reshape(aDT,(3,3)).real\n",
    "\n",
    "    # END: construct axonal DT (aDT)\n",
    "\n",
    "    # BEGIN: FBWM portion...\n",
    "    if fbwm_flag == 1:\n",
    "\n",
    "        f_grid = np.linspace(0,1,100) # define AWF grid (100 pts evenly spaced between 0 (min) and 1 (max))\n",
    "        f_grid = f_grid * np.ones((1,100)) # makes it in to a proper array...weird but it works\n",
    "\n",
    "        int_grid = np.linspace(0,99,100) # define grid points to iterate over (100 of them)\n",
    "        int_grid = int_grid * np.ones((1,100)) # same as above, makes it a proper array object...?\n",
    "\n",
    "        # This holds the SH basis sets for each b-value shell\n",
    "        shB = [B1,B2,B] # list object: to access, shB[0] = B1 (for example)\n",
    "\n",
    "        imgn1 = img1[:,vox] # b1000 DWI images\n",
    "        imgn2 = img2[:,vox] # b2000 DWI images\n",
    "\n",
    "        # This hold all DWI volumes for each b-vlaue shell\n",
    "        IMG = [imgn1, imgn2, imgn] # list object: to access, IMG[0] = imgn1 (for example)\n",
    "\n",
    "        # BEGIN: DT construction (should be modified to fit with PyDesigner output)\n",
    "        # This is based on DKE DT output as of 05/05/2020\n",
    "        iDT = np.array([DT[vox,0],DT[vox,3],DT[vox,4],DT[vox,3],DT[vox,1],DT[vox,5],DT[vox,4],DT[vox,5],DT[vox,2]])\n",
    "        iDT = np.reshape(iDT,(3,3))\n",
    "        # END: DT construction\n",
    "\n",
    "        # initialze correction factor elements that will be looped over and filled accordingly...\n",
    "        g2l_fa_R = np.zeros((len(harmonics),f_grid.shape[1]), order = 'F')\n",
    "        g2l_fa_R_b = np.zeros((len(BT),f_grid.shape[1],len(harmonics)), order = 'F')\n",
    "        g2l_fa_R_large = np.zeros((len(harmonics),f_grid.shape[1]), order = 'F')\n",
    "\n",
    "\n",
    "\n",
    "        # BEGIN: cost function\n",
    "        # Not many comments here, See McKinnon 2018 FBWm paper for details\n",
    "        for b in range(0,len(BT)):\n",
    "\n",
    "            idx_hyper = BT[b] * np.power(f_grid,2) * np.power(zeta[vox],-2) < 20 # when should hypergeometric function be implemented? When b*D is small\n",
    "            idx_Y = 0\n",
    "\n",
    "            for l in degs[::2]:\n",
    "\n",
    "                hypergeom_opt = np.sum((sp.special.gamma((l+1)/2 + int_grid) * sp.special.gamma(l+(3/2)) * ((-BT[b] * f_grid[idx_hyper]**2 * zeta[vox]**-2)*np.ones((1,len(f_grid[idx_hyper])))).T ** int_grid / (sp.special.factorial(int_grid) * sp.special.gamma(l+(3/2) + int_grid) * sp.special.gamma((l+1)/2))),1)*np.ones((1,len(f_grid[idx_hyper])))\n",
    "                g2l_fa_R[idx_Y:idx_Y+(2*l+1),np.squeeze(idx_hyper)] = npm.repmat((sp.special.factorial(l/2) * (BT[b] * f_grid[idx_hyper]**2 * zeta[vox]**-2) ** ((l+1)/2) / sp.special.gamma(l+(3/2)) * hypergeom_opt),(2*l+1),1) # Eq. 9 FBWM paper\n",
    "                idx_Y = idx_Y + (2*l+1)\n",
    "\n",
    "            g2l_fa_R_b[b,np.squeeze(idx_hyper),:] = g2l_fa_R[:,np.squeeze(idx_hyper)].T\n",
    "\n",
    "            idx_Y = 0\n",
    "\n",
    "            for l in degs[::2]:\n",
    "\n",
    "                g2l_fa_R_large[idx_Y:idx_Y+(2*l+1), np.squeeze(~idx_hyper)] = npm.repmat((np.exp(-l/2 * (l+1) / ((2*BT[b] * (f_grid[~idx_hyper]**2 * zeta[vox]**-2))))),(2*l+1),1) # Eq. 20 FBI paper\n",
    "                idx_Y = idx_Y + (2*l+1)\n",
    "\n",
    "            g2l_fa_R_b[b,np.squeeze(~idx_hyper),:] = g2l_fa_R_large[:,np.squeeze(~idx_hyper)].T\n",
    "\n",
    "        # here is the core piece of the cost function:\n",
    "        for grid in np.squeeze(int_grid.astype('int')):\n",
    "            for b in range(0,len(BT)):\n",
    "\n",
    "                awf = f_grid[:,grid] # define AWF grid\n",
    "\n",
    "                # Se and Sa are the theoretical extra-axonal and intra-axonal signals that will be compared with IMG[:] DWI values for each voxel element\n",
    "                Se = (b0n * np.exp((-BT[b] * (1-awf)**-1) * np.diag((GT[b].dot((iDT - (awf**3 * zeta[vox]**-2) * iaDT).dot(GT[b].T)))))) * (1 - awf) # Eq. 3 FBWM paper\n",
    "                Sa = (2*np.pi*b0n*zeta[vox]*np.sqrt(np.pi/BT[b])) * (shB[b].dot((Pl0 * np.squeeze(g2l_fa_R_b[b,grid,:])*clm))) # Eq. 4 FBM paper\n",
    "\n",
    "                cost_fn[grid,vox] = cost_fn[grid,vox] + ndir[b]**-1 * np.sum((IMG[b] - Se - Sa)**2)\n",
    "\n",
    "            cost_fn[grid,vox] = b0n**-1 * np.sqrt(len(BT)**-1 * cost_fn[grid,vox]) # Eq. 21 FBWM paper\n",
    "\n",
    "            iDT_img[:,:,vox] = iDT\n",
    "            iaDT_img[:,:,vox] = iaDT\n",
    "\n",
    "if fbwm_flag == 1:\n",
    "\n",
    "    min_cost_fn_idx = np.argsort(cost_fn, axis = 0) # find the indexes of the sorted cost_fn values\n",
    "    min_cost_fn = np.take_along_axis(cost_fn,min_cost_fn_idx,axis=0) # sort those values\n",
    "\n",
    "    awf_grid = np.linspace(0,1,100) # another AWF grid\n",
    "\n",
    "    min_awf = awf_grid[min_cost_fn_idx[0,:]] # grad the minimum AWF value based on the cost_fn sorting done immeidately prior to this...\n",
    "\n",
    "    Da = min_awf**2 / zeta**2 # Eq. 22 McKinnon (2018). intrinsic intra-axonal diffusivity\n",
    "\n",
    "    # loop over the voxels to get extra-axonal diffusion tensor (De)...\n",
    "    for vox in inputs:\n",
    "\n",
    "        De[:,:,vox] = (iDT_img[:,:,vox] - (min_awf[vox]**3 * zeta[vox]**-2) * iaDT_img[:,:,vox]) / (1 - min_awf[vox])\n",
    "\n",
    "        iDe = De[:,:,vox] # intermeidate De\n",
    "        iDe[np.isnan(iDe)] = 0\n",
    "        iDe[np.isinf(iDe)] = 0\n",
    "        L,V = np.linalg.eig(iDe) # L : eigVals and V: eigVecs\n",
    "        L = np.sort(L) # sort them (this is ascending)\n",
    "        L = L[::-1] # reverse the order so they are descending (high -> low)\n",
    "\n",
    "        N = 1 # initialize counter\n",
    "\n",
    "        while L[0] < 0 or L[1] < 0 or L[2] < 0: # find new AWF values if L's are < 0\n",
    "\n",
    "            N = N + 1\n",
    "\n",
    "            if N < 100:\n",
    "\n",
    "                min_awf[vox] = awf_grid[min_cost_fn_idx[N,vox]]\n",
    "\n",
    "            else:\n",
    "\n",
    "                min_awf[vox] = 0\n",
    "                De[:,:,vox] = (iDT_img[:,:,vox] - (min_awf[vox]**3 * zeta[vox]**-2) * iaDT_img[:,:,vox]) / (1 - min_awf[vox])\n",
    "                Da[vox] = min_awf[vox]**2 / zeta[vox]**2\n",
    "\n",
    "                break\n",
    "\n",
    "            # update De here...\n",
    "            De[:,:,vox] = (iDT_img[:,:,vox] - (min_awf[vox]**3 * zeta[vox]**2) * iaDT_img[:,:,vox]) / (1 - min_awf[vox])\n",
    "            Da[vox] = min_awf[vox]**2 / zeta[vox]**2 # recalculate Da too...\n",
    "\n",
    "        # Now recalculate eigVals again with correct AWF values\n",
    "\n",
    "        iDe = De[:,:,vox]\n",
    "        iDe[np.isnan(iDe)] = 0\n",
    "        iDe[np.isinf(iDe)] = 0\n",
    "        L,V = np.linalg.eig(iDe) # L : eigVals and V: eigVecs\n",
    "        L = np.sort(L) # again, ascending\n",
    "        L = L[::-1] # now, descending\n",
    "\n",
    "        De_ax[vox] = L[0] # Eq. 24 FBWM paper, axial extra-axonal diffusivity\n",
    "        De_rad[vox] = (L[1] + L[2])/2 # radial De\n",
    "        De_fa[vox] = np.sqrt(((L[0] - L[1]) ** 2 + (L[0] - L[2]) ** 2 + (L[1] - L[2]) ** 2 ) / (2 * np.sum(L ** 2))) # extra-axonal FA\n",
    "        De_mean[vox] = (1/3) * (2 * De_rad[vox] + De_ax[vox]) # average De\n",
    "\n",
    "    De[np.isnan(De)] = 0\n",
    "    De[np.isinf(De)] = 0\n",
    "\n",
    "\n",
    "# HERE IS WHERE IMAGES ARE READ OUT....\n",
    "# need to automate dimension pull and reshape...\n",
    "\n",
    "zeta = np.reshape(zeta,(74,74,42), order = 'F')\n",
    "faa = np.reshape(faa,(74,74,42), order = 'F')\n",
    "\n",
    "zetaImg = nib.Nifti1Image(zeta,hdr.affine,hdr.header)\n",
    "faaImg = nib.Nifti1Image(faa,hdr.affine,hdr.header)\n",
    "\n",
    "zetaImg.to_filename(op.join(root,'zeta.nii'))\n",
    "faaImg.to_filename(op.join(root,'faa.nii'))\n",
    "\n",
    "if fbwm_flag == 1:\n",
    "\n",
    "    min_awf = np.reshape(min_awf,(74,74,42), order = 'F')\n",
    "    Da = np.reshape(Da,(74,74,42), order = 'F')\n",
    "    De_mean = np.reshape(De_mean,(74,74,42), order = 'F')\n",
    "    De_ax = np.reshape(De_ax,(74,74,42), order = 'F')\n",
    "    De_rad = np.reshape(De_rad,(74,74,42), order = 'F')\n",
    "    De_fa = np.reshape(De_fa,(74,74,42), order = 'F')\n",
    "    min_cost_fn = np.reshape(min_cost_fn[0,:],(74,74,42), order = 'F')\n",
    "\n",
    "    awfImg = nib.Nifti1Image(min_awf,hdr.affine,hdr.header)\n",
    "    DaImg = nib.Nifti1Image(Da,hdr.affine,hdr.header)\n",
    "    De_meanImg = nib.Nifti1Image(De_mean,hdr.affine,hdr.header)\n",
    "    De_axImg = nib.Nifti1Image(De_ax,hdr.affine,hdr.header)\n",
    "    De_radImg = nib.Nifti1Image(De_rad,hdr.affine,hdr.header)\n",
    "    De_faImg = nib.Nifti1Image(De_fa,hdr.affine,hdr.header)\n",
    "    minCostImg = nib.Nifti1Image(min_cost_fn,hdr.affine,hdr.header)\n",
    "\n",
    "    awfImg.to_filename(op.join(root,'awf.nii'))\n",
    "    DaImg.to_filename(op.join(root,'da.nii'))\n",
    "    De_meanImg.to_filename(op.join(root,'de_mean.nii'))\n",
    "    De_axImg.to_filename(op.join(root,'de_ax.nii'))\n",
    "    De_radImg.to_filename(op.join(root,'de_rad.nii'))\n",
    "    De_faImg.to_filename(op.join(root,'fae.nii'))\n",
    "    minCostImg.to_filename(op.join(root,'minCost.nii'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
